{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to look at variational autoencoders and denoising autoencoders. I've designed this workbook as an example of what can be used as a workbook for a session on VAEs and denoising autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started with variational autoencoders and denoising autoencoders, let's review regular autoencoders. An autoencoder is a type of artificial neural network that is used in representation learning. That means it can be used to learn a compact representation of an input data set, called an encoding, through the use of unsupervised learning. The autoencoder is trained to reconstruct the original input data from this encoding. An autoencoder consists of two main components: the encoder and the decoder. The encoder processes the input data and learns a compressed representation of it, called the encoding, by minimizing the reconstruction loss, which is the difference between the input data and the reconstructed data. The decoder processes the encoding and generates a reconstruction of the original input data. Here's a simple visual that helps to understand what's going on:\n",
    "\n",
    "![Autoencoder Image](autoencoder.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what the basic autoencoder architecture looks like, we can move onto VAEs and denoising autoencoders. Do the folloing readings by focusing on the description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Aurélien Géron (2019) Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. Chapter 17](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "\n",
    "- Focus on page 586-591. You should aim to understand what makes VAEs probabilistic and generative models. Make sure you also understand why we add the latent loss term, and why the latent loss equal to minimizing the KL divergnece between the Standard Normal distribution and the target distribution.\n",
    "\n",
    "[Optional] [DigitalSreeni (Nov 26, 2020), 178 - An introduction to variational autoencoders (VAE)](https://www.youtube.com/watch?v=YV9D3TWY5Zo)\n",
    "\n",
    "- If you're a visual learner, this video can complement what is in the readings. It also explains how the training works by explaining how we use KL divergence to minimize the distance between the Standard Normal distribution and the target distribution.\n",
    "\n",
    "[Optional] [Kingma, D. P., & Welling, M. (2013). Auto-Encoding Variational Bayes](https://doi.org/10.48550/arXiv.1312.6114)\n",
    "\n",
    "- If you want to read more on VAEs, this is the original paper that introduced the idea. It discusses the idea that we can use Variational Bayesian Inference to approximate the posterior and create the Normal distribution, which we can then sample from to pass to our decoder.\n",
    "\n",
    "\n",
    "[Aurélien Géron (2019) Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. Chapter 17](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "\n",
    "- For denoising autoencoders, focus on page 581-582. Make sure you understand the different ways we can construct denoising autoencoders and how they build upon regular autoencoders\n",
    "\n",
    "[Optional] [Developers Hutt (Jan 10, 2021), Denoising AutoEnocoder || Autoencoders || Developers Hutt](https://www.youtube.com/watch?v=ebPq0cILZV8)\n",
    "\n",
    "- This video is also a good complement to the reading above\n",
    "\n",
    "[Optional] [Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., & Manzagol, P.-A. (2010). Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion. Journal of Machine Learning Research, 11(110), 3371–3408.](http://jmlr.org/papers/v11/vincent10a.html)\n",
    "\n",
    "- This is the original paper on denoising autoencoders if you want to read further\n",
    "\n",
    "[Google Cloud Tech (Aug 14, 2018), Getting Started with Keras](https://www.youtube.com/watch?v=J6Ok8p463C4&t=317s)\n",
    "\n",
    "- This short video will help you get started with the keras API using TensorFlow. This will be helpful for the implementation we'll do in the workbook below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Basic Questions\n",
    "\n",
    "1. Intuitively explain what VAEs and denoising autoencoders are and what makes them different from regular autoencoders.\n",
    "2. What are the different ways we can create denoising autoencoders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Core Questions\n",
    "\n",
    "The code cell below creates the encoder network for a VAE. Explain what each line is doing. Specifically, explain the following:\n",
    "- How many layers do we have in the encoder?\n",
    "- How many neurons do we have in each layer?\n",
    "- What is the size of the image that the encoder accepts and what is its output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 10\n",
    "\n",
    "inputs = keras.layers.Input(shape=[28, 28])\n",
    "z = keras.layers.Flatten()(inputs)\n",
    "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
    "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
    "codings_mean = keras.layers.Dense(codings_size)(z) \n",
    "codings_log_var = keras.layers.Dense(codings_size)(z) \n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = keras.Model(inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below contains that code for creating a denoising autoencoder by adding Gaussian noise to the input. Use the same outline to create one that instead uses dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising Autoencoder by adding a Gaussian Noise\n",
    "\n",
    "codings_size = 10  \n",
    "\n",
    "# create the encoder with two hidden layers\n",
    "denoising_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.GaussianNoise(0.2),  # gaussian noise added\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(codings_size, activation=\"selu\")\n",
    "])\n",
    "\n",
    "# create the decoder with two hidden layers\n",
    "denoising_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])  # connect the decoder and encoder\n",
    "denoising_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the denoising autoencoder with dropout here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Extension Questions\n",
    "\n",
    "We said that for VAEs, we can sample from the Normal distribution created to then pass on to the decoder network to get an output. The following code can sample from the Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "# Helps with sampling from the Normal distribution created by the encoder. We then feed this to the decoder\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we are using mean and log_var instead of regular mean and variance for our Normal distribution. Why are we taking the log of the variance? What problem does that solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the autoencoders we've used so far, we used feedforward neural networks in both our encoder and decoder networks. But since we're working with images, convolutional neural networks might do a better job. Therefore, in the code cell below, create a variational autoencoder that uses convolutional neural networks in the encoder and decoder networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('cs156')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ea1543db10da00b3772d536e7bf85d913232dd60f1fff3121913df4583eda6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
